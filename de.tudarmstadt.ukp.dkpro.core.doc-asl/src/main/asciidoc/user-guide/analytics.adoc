// Copyright 2013
// Ubiquitous Knowledge Processing (UKP) Lab
// Technische Universit√§t Darmstadt
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

[[sect_analytics]]

== Analysis Components

This section provides an overview of the analysis componens that can be deployed at the
different levels of analysis.

=== Coreference Resolution

.Coreference types
image::ts_coreference.png[align="center"]

.Coreference components
[options="header"]
|====
|Component|Description
|StanfordCoreferenceResolver
|
|====


=== Chunking

.Chunking components
[options="header"]
|====
|Component|Description
|OpenNlpChunker|

|TreeTaggerChunker
|(uses native binary)
|====


=== Decompounding

.Decompounding components
[options="header"]
|====
|Component|Description
|CompoundAnnotator
|
|====


=== Dictionary-Based Annotation

.Dictionary-based annotation components
[options="header"]
|====
|Component|Description
|DictionaryAnnotator
|

|SemanticFieldAnnotator
|
|====


=== Language Identification

.DocumentAnnotation type
image::ts_document_meta_data.png[align="center"]

.Language identification components
[options="header"]
|====
| Component|Description
| LangDetectLanguageIdentifier
| Detection based on character n-grams.

| LanguageDetectorWeb1T
| Detection based on token n-grams.

| TextCat
| Detection based on character n-grams. Used the link:http://textcat.sourceforge.net[Java Text Categorizing Library]
  based on a technique by Cavnar and Trenkle <<Cavnar:1994>>.
|====


=== Lemmatization

.Lemma type
image::ts_lemmatization.png[align="center"]

.Lemmatization components
[options="header"]
|====
|Component|Description
|ClearNlpLemmatizer
|

|GateLemmatizer
|

|LanguageToolLemmatizer
|

|MateLemmatizer
|

| MorphaLemmatizer
| Lemmatize based on a finite-state machine. Uses the link:https://github.com/knowitall/morpha[Java
  port] of link:http://www.informatics.sussex.ac.uk/research/groups/nlp/carroll/morph.html[Morpha].
  <<MinnenEtal:2001>>.

|StanfordLemmatizer
|(variant of Morpha)

|TreeTaggerPosTagger
|(uses native binary)
|====


=== Morphological Analysis

.Morphological analysis components
[options="header"]
|====
|Component|Description
|MateMorphTagger
|

|SfstAnnotator
|(uses native binary)

|RfTagger
|(uses native binary)
|====


=== Named-Entity Recognition

.Named-entity recognition components
[options="header"]
|====
|Component|Description
| OpenNlpNameFinder
|

| StanfordNamedEntityRecognizer
|
|====

=== Normalization

.Text normalization components
[options="header"]
|====
|Component|Description
| CjfNormalizer
| Converts traditional Chinese to simplified Chinese or vice-versa.

| CapitalizationNormalizer
| 

| DictionaryBasedTokenTransformer
| 

| ExpressiveLengtheningNormalizer
| 

| HyphenationRemover
| 

| SharpSNormalizer
| 

| SpellingNormalizer
| 

| StanfordPtbTransformer
| 

| TokenCaseTransformer
| 

| UmlautNormalizer
|====


=== Parsing

.Parsing components
[options="header"]
|====
|Component|Description
|BerkeleyParser
|constituents

|ClearNlpDependencyParser
|dependencies

|OpenNlpParser
|constituents

|MaltParser
|dependencies

|MateParser
|dependencies

|MstParser
|dependencies

|StanfordParser
|constituents, dependencies (for some languages)
|====


=== Part-of-Speech Tagging

.Part-of-speech type
image::ts_part-of-speech.png[align="center"]

.Part-of-speech tagging components
[options="header"]
|====
|Component|Description
|ArktweetTagger
|

|ClearNlpPosTagger
|

|HepplePosTagger
|

|HunPosTagger
|(uses native binary)

// | LbjPosTagger
// | (not in release)

|MatePosTagger
|

|MeCabTagger
|(uses native binary)

|OpenNlpPosTagger
|

|StanfordPosTagger
|

|TreeTaggerPosTagger
|also does lemmatization (uses native binary)
|====


=== Segmentation

Segmenter components identify sentence boundaries and tokens. The order in which sentence
splitting and tokenization are done differs between the integrated the NLP libraries.
Thus, we chose to integrate both steps into a segmenter component to avoid the need to
reorder the components in a pipeline when replacing one segmenter with another.

.Segmentation types
image::ts_segmentation.png[align="center"]

.Segmentation components
[options="header"]
|====
|Component|Description
|BreakIteratorSegmenter
|

|ClearNlpSegmenter
|

|JTokSegmenter
|

|LanguageToolSegmenter
|

|OpenNlpSegmenter
|

|StanfordSegmenter
|
|====


=== Semantic Role Labeling

.Semantic role labeling types
image::ts_semantics.png[align="center"]

.Semantic role labeling components
[options="header"]
|====
|Component|Description
|ClearNlpSemanticRoleLabeler
|
|====


=== Spell Checking

.Spell checking components
[options="header"]
|====
|Component|Description
|LanguageToolChecker
|

|NorvigSpellingCorrector
|

|JazzyChecker
|
|====


=== Stemming

.Stem type
image::ts_stemming.png[align="center"]

.Stemming components
[options="header"]
|====
|Component|Description
|SnowballStemmer
|
|====


=== Topic Modeling

Topic modeling is a statistical approach to discover abstract _topics_ in a collection of documents. 
A topic is characterized by a probability distribution of the words in the document collection.
Once a topic model has been generated, it can be used to analyze unseen documents. The result of the
analysis is describes the probability by which a document _belongs_ to each of the _topics_ in the
model.

.Topic model type
image::ts_topicmodel.png[align="center"]

.Topic modeling components
[options="header"]
|====
|Component|Description
| MalletTopicModelEstimator
| Estimate a topic model using Mallet and write it to a file.
| MalletTopicModelInferencer
| Detect the topic distribution in documents.
|====

